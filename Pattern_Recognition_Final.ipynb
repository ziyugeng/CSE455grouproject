{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1. Load all the necessary functions"
      ],
      "metadata": {
        "id": "LJLks1ivtlPN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TfErQcl66_yl"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "from sklearn.model_selection import train_test_split\n",
        "import requests\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. import CNN/Daily Mail dataset, from https://huggingface.co/datasets/cnn_dailymail"
      ],
      "metadata": {
        "id": "bbWP2rA3uDUm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# follow the instruction from https://huggingface.co/docs/datasets-server/quick_start\n",
        "# Ziyu Geng\n",
        "\n",
        "# This is English version now, sorry for import wrong dataset.\n",
        "\n",
        "API_URL = \"https://datasets-server.huggingface.co/splits?dataset=cnn_dailymail\"  # contains train, val, and test\n",
        "def query():\n",
        "    response = requests.get(API_URL)\n",
        "    return response.json()\n",
        "data = query()\n",
        "print(data)\n",
        "\n",
        "# train\n",
        "API_URL = \"https://datasets-server.huggingface.co/rows?dataset=cnn_dailymail&config=1.0.0&split=train&offset=0&limit=100\"  # train\n",
        "def train_query():\n",
        "    response = requests.get(API_URL)\n",
        "    return response.json()\n",
        "train_data = train_query()\n",
        "print(train_data)\n",
        "\n",
        "# val\n",
        "API_URL = \"https://datasets-server.huggingface.co/rows?dataset=cnn_dailymail&config=1.0.0&split=validation&offset=0&limit=100\"  # validation\n",
        "def val_query():\n",
        "    response = requests.get(API_URL)\n",
        "    return response.json()\n",
        "val_data = val_query()\n",
        "print(val_data)\n",
        "\n",
        "# test\n",
        "API_URL = \"https://datasets-server.huggingface.co/rows?dataset=cnn_dailymail&config=1.0.0&split=test&offset=0&limit=100\"  # test\n",
        "def test_query():\n",
        "    response = requests.get(API_URL)\n",
        "    return response.json()\n",
        "test_data = test_query()\n",
        "print(test_data)"
      ],
      "metadata": {
        "id": "1-U7rEkVuDnF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "#1 tokenize text to individual words or subwords, remove stopwords, punctuation and special characters, and make them all lowercase\n",
        "\n",
        "def preprocess_text(text):\n",
        "    # tokenize text into words\n",
        "    words = word_tokenize(text)\n",
        "\n",
        "    # remove punctuation and special characters\n",
        "    table = str.maketrans('', '', string.punctuation)\n",
        "    words = [word.translate(table) for word in words]\n",
        "\n",
        "    # convert words to lowercase\n",
        "    words = [word.lower() for word in words]\n",
        "\n",
        "    # remove stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    words = [word for word in words if word not in stop_words]\n",
        "\n",
        "    # remove empty strings/single characters\n",
        "    words = [word for word in words if len(word) > 1]\n",
        "\n",
        "    return words\n",
        "\n",
        "#2 pad/truncate text to make all samples have the same length\n",
        "\n",
        "def pad_or_truncate_text(text, max_length):\n",
        "    # preprocess the text\n",
        "    preprocessed_text = preprocess_text(text)\n",
        "\n",
        "    # truncate text if longer than max_length\n",
        "    if len(preprocessed_text) > max_length:\n",
        "        preprocessed_text = preprocessed_text[:max_length]\n",
        "\n",
        "    # pad text if shorter than max_length\n",
        "    elif len(preprocessed_text) < max_length:\n",
        "        padding_length = max_length - len(preprocessed_text)\n",
        "        preprocessed_text.extend(['<PAD>'] * padding_length)\n",
        "\n",
        "    return preprocessed_text\n",
        "\n",
        "max_length = 800  # <-----should be roughly how many words/tokens are in each article\n",
        "\n",
        "#\n",
        "\n",
        "train_texts = []\n",
        "val_texts = []\n",
        "test_texts = []\n",
        "\n",
        "for example in train_data['rows']:\n",
        "    article_text = example['row']['article']\n",
        "    preprocessed_text = pad_or_truncate_text(article_text, max_length)\n",
        "    train_texts.append(preprocessed_text)\n",
        "\n",
        "for example in test_data['rows']:\n",
        "    article_text = example['row']['article']\n",
        "    preprocessed_text = pad_or_truncate_text(article_text, max_length)\n",
        "    test_texts.append(preprocessed_text)\n",
        "\n",
        "for example in val_data['rows']:\n",
        "    article_text = example['row']['article']\n",
        "    preprocessed_text = pad_or_truncate_text(article_text, max_length)\n",
        "    val_texts.append(preprocessed_text)\n",
        "\n",
        "print(train_texts)\n",
        "print(val_texts)\n",
        "print(test_texts)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5lj9zMcIoDBX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Represent text as word embeddigs\n",
        "\n",
        "# -Word emeddings examples are Word2Vec, GloVe, FastText and represent each word as dense vector\n",
        "# Ziyu Geng, follow https://pytorch.org/tutorials/beginner/nlp/word_embeddings_tutorial.html.\n",
        "\n",
        "# sorry guys, I did not find the Word2Vec pytorch material, so I did not use it, if you guys find something error, feel free to correct.\n",
        "\n",
        "embedding_dim = 10 # same number from https://pytorch.org/tutorials/beginner/nlp/word_embeddings_tutorial.html\n",
        "torch.manual_seed(1)\n",
        "\n",
        "# list of train texts\n",
        "train_preprocessed_text = []\n",
        "for example in train_data['rows']:\n",
        "  article_text = example['row']['article']\n",
        "  train_preprocessed_text.append(pad_or_truncate_text(article_text, max_length))\n",
        "\n",
        "val_preprocessed_text = []\n",
        "for example in val_data['rows']:\n",
        "  article_text = example['row']['article']\n",
        "  val_preprocessed_text.append(pad_or_truncate_text(article_text, max_length))\n",
        "\n",
        "# list of test texts\n",
        "test_preprocessed_text = []\n",
        "for example in test_data['rows']:\n",
        "  article_text = example['row']['article']\n",
        "  test_preprocessed_text.append(pad_or_truncate_text(article_text, max_length))\n",
        "\n",
        "# build vocabulary\n",
        "voc = set()\n",
        "all_texts = train_preprocessed_text + val_preprocessed_text + test_preprocessed_text\n",
        "for sentence in all_texts:\n",
        "    for word in sentence:\n",
        "        voc.add(word)\n",
        "\n",
        "# make word to number\n",
        "word_to_num = {}\n",
        "i = 0\n",
        "for word in voc:\n",
        "    word_to_num[word] = i\n",
        "    i += 1\n",
        "\n",
        "class wordembedding(nn.Module):\n",
        "  def __init__(self, vocab_size, embedding_dim):\n",
        "    super(wordembedding, self).__init__()\n",
        "    self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "  def forward(self, inputs):\n",
        "    return self.embeddings(inputs)\n",
        "\n",
        "# Create the model and the optimizer\n",
        "word_model = wordembedding(len(voc), embedding_dim)\n",
        "optimizer = optim.SGD(word_model.parameters(), lr=0.001)\n",
        "\n",
        "# loop train_preprocessed_text and generate embeddings\n",
        "for sentence in train_preprocessed_text:\n",
        "  sentence_idxs = []\n",
        "  for word in sentence:\n",
        "    id = word_to_num[word]  # Get the index of the word\n",
        "    sentence_idxs.append(id)  # Append the index to the list\n",
        "\n",
        "  sentence_idxs = torch.tensor(sentence_idxs, dtype=torch.long)  # Convert the list to tensor outside the loop\n",
        "  word_model.zero_grad()\n",
        "  embeddings = word_model(sentence_idxs)\n",
        "\n",
        "  print(embeddings)\n",
        "\n",
        "for sentence in val_preprocessed_text:\n",
        "   sentence_idxs = []\n",
        "   for word in sentence:\n",
        "    id = word_to_num[word]  # Get the index of the word\n",
        "    sentence_idxs.append(id)  # Append the index to the list\n",
        "\n",
        "   sentence_idxs = torch.tensor(sentence_idxs, dtype=torch.long)  # Convert the list to tensor outside the loop\n",
        "   word_model.zero_grad()\n",
        "   embeddings = word_model(sentence_idxs)\n",
        "\n",
        "   print(embeddings)\n",
        "\n",
        "\n",
        "for sentence in test_preprocessed_text:\n",
        "   sentence_idxs = []\n",
        "   for word in sentence:\n",
        "    id = word_to_num[word]  # Get the index of the word\n",
        "    sentence_idxs.append(id)  # Append the index to the list\n",
        "\n",
        "   sentence_idxs = torch.tensor(sentence_idxs, dtype=torch.long)  # Convert the list to tensor outside the loop\n",
        "   word_model.zero_grad()\n",
        "   embeddings = word_model(sentence_idxs)\n",
        "\n",
        "   print(embeddings)\n",
        "\n",
        "# ... (Same as before)\n",
        "\n",
        "train_embeddings_list = []\n",
        "val_embeddings_list = []\n",
        "test_embeddings_list = []\n",
        "\n",
        "# loop train_preprocessed_text and generate embeddings\n",
        "for sentence in train_preprocessed_text:\n",
        "    sentence_idxs = []\n",
        "    for word in sentence:\n",
        "        id = word_to_num[word]  # Get the index of the word\n",
        "        sentence_idxs.append(id)  # Append the index to the list\n",
        "\n",
        "    sentence_idxs = torch.tensor(sentence_idxs, dtype=torch.long)  # Convert the list to tensor outside the loop\n",
        "    word_model.zero_grad()\n",
        "    embeddings = word_model(sentence_idxs)\n",
        "    train_embeddings_list.append(embeddings.detach())  # Store the embeddings\n",
        "\n",
        "# loop val_preprocessed_text and generate embeddings\n",
        "for sentence in val_preprocessed_text:\n",
        "    sentence_idxs = []\n",
        "    for word in sentence:\n",
        "        id = word_to_num[word]  # Get the index of the word\n",
        "        sentence_idxs.append(id)  # Append the index to the list\n",
        "\n",
        "    sentence_idxs = torch.tensor(sentence_idxs, dtype=torch.long)  # Convert the list to tensor outside the loop\n",
        "    word_model.zero_grad()\n",
        "    embeddings = word_model(sentence_idxs)\n",
        "    val_embeddings_list.append(embeddings.detach())  # Store the embeddings\n",
        "\n",
        "# loop test_preprocessed_text and generate embeddings\n",
        "for sentence in test_preprocessed_text:\n",
        "    sentence_idxs = []\n",
        "    for word in sentence:\n",
        "        id = word_to_num[word]  # Get the index of the word\n",
        "        sentence_idxs.append(id)  # Append the index to the list\n",
        "\n",
        "    sentence_idxs = torch.tensor(sentence_idxs, dtype=torch.long)  # Convert the list to tensor outside the loop\n",
        "    word_model.zero_grad()\n",
        "    embeddings = word_model(sentence_idxs)\n",
        "    test_embeddings_list.append(embeddings.detach())  # Store the embeddings\n",
        "\n",
        "# Convert lists to PyTorch tensors\n",
        "train_embeddings_tensor = torch.stack(train_embeddings_list)\n",
        "val_embeddings_tensor = torch.stack(val_embeddings_list)\n",
        "test_embeddings_tensor = torch.stack(test_embeddings_list)\n",
        "\n"
      ],
      "metadata": {
        "id": "Br1C0TEegt3k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import tqdm\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "KN0X7MAdorkG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define NN architecture\n",
        "\n",
        "# some suggested are RNN, LSTM, or Transformer based models\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "embedding_dim = 10\n",
        "hidden_dim = 256\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
        "\n",
        "    def forward(self, input_sequence):\n",
        "        embedded_input = self.embedding(input_sequence)\n",
        "        encoder_outputs, (hidden_state, cell_state) = self.rnn(embedded_input)\n",
        "        return encoder_outputs, (hidden_state, cell_state)\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, hidden_dim):\n",
        "        super(Attention, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.attn = nn.Linear(hidden_dim * 2, hidden_dim)\n",
        "        self.v = nn.Parameter(torch.rand(hidden_dim))\n",
        "\n",
        "    def forward(self, hidden, encoder_outputs):\n",
        "        max_len = encoder_outputs.size(1)\n",
        "        h = hidden.repeat(max_len, 1, 1).transpose(0, 1)\n",
        "        encoder_outputs = encoder_outputs.transpose(1, 2)\n",
        "        attn_scores = F.softmax(torch.bmm(h, self.attn(encoder_outputs)), dim=2)\n",
        "        context = torch.bmm(attn_scores, encoder_outputs).squeeze(1)\n",
        "        return context\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.rnn = nn.LSTM(embedding_dim + hidden_dim, hidden_dim, batch_first=True)\n",
        "        self.attention = Attention(hidden_dim)\n",
        "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
        "\n",
        "    def forward(self, input_sequence, hidden, encoder_outputs):\n",
        "        embedded_input = self.embedding(input_sequence)\n",
        "        context = self.attention(hidden, encoder_outputs)\n",
        "        rnn_input = torch.cat((embedded_input, context.unsqueeze(1)), dim=2)\n",
        "        decoder_outputs, hidden = self.rnn(rnn_input, hidden)\n",
        "        output_sequence = F.log_softmax(self.fc(decoder_outputs.squeeze(1)), dim=1)\n",
        "        return output_sequence, hidden\n",
        "\n",
        "class Seq2SeqAttention(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
        "        super(Seq2SeqAttention, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.encoder = Encoder(vocab_size, embedding_dim, hidden_dim)\n",
        "        self.decoder = Decoder(vocab_size, embedding_dim, hidden_dim)\n",
        "\n",
        "    def forward(self, source_sequence, target_sequence):\n",
        "        embedded_source = self.embedding(source_sequence)\n",
        "        embedded_target = self.embedding(target_sequence)\n",
        "\n",
        "        encoder_outputs, hidden = self.encoder(embedded_source)\n",
        "        batch_size, target_length = target_sequence.size(0), target_sequence.size(1)\n",
        "        outputs = torch.zeros(batch_size, target_length, vocab_size).to(target_sequence.device)\n",
        "        decoder_input = embedded_target[:, 0].unsqueeze(1)\n",
        "        for t in range(1, target_length):\n",
        "            output, hidden = self.decoder(decoder_input, hidden, encoder_outputs)\n",
        "            outputs[:, t] = output\n",
        "            decoder_input = embedded_target[:, t].unsqueeze(1)\n",
        "        return outputs\n",
        "\n",
        "# Assuming you already have the following tensors:\n",
        "# train_embeddings_tensor, val_embeddings_tensor, test_embeddings_tensor\n",
        "\n",
        "final_train_dataset = TensorDataset(train_embeddings_tensor)\n",
        "final_val_dataset = TensorDataset(val_embeddings_tensor)\n",
        "final_test_dataset = TensorDataset(test_embeddings_tensor)\n",
        "\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(final_train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(final_val_dataset, batch_size=batch_size)\n",
        "test_loader = DataLoader(final_test_dataset, batch_size=batch_size)\n",
        "\n",
        "# instantiate model\n",
        "vocab_size = len(voc)\n",
        "model = Seq2SeqAttention(vocab_size, embedding_dim, hidden_dim)\n",
        "\n",
        "# loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
      ],
      "metadata": {
        "id": "QFDixK8oh9iB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from tqdm import tqdm\n",
        "\n",
        "num_epochs = 20\n",
        "plot_interval = 5\n",
        "\n",
        "train_loss_list = []\n",
        "val_loss_list = []\n",
        "train_accuracy_list = []\n",
        "val_accuracy_list = []\n",
        "\n",
        "def calculate_accuracy(output_sequence, target_sequence):\n",
        "    _, predicted = torch.max(output_sequence, 1)\n",
        "    correct = (predicted == target_sequence).sum().item()\n",
        "    total = target_sequence.size(0)\n",
        "    accuracy = correct / total\n",
        "    return accuracy\n",
        "\n",
        "for epoch in tqdm(range(num_epochs), desc=\"Epochs\"):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    total_accuracy = 0.0\n",
        "\n",
        "    # train\n",
        "    for source_batch in tqdm(train_loader, desc=\"Training Batches\", leave=False):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        source_batch = torch.stack(source_batch, dim=0)\n",
        "\n",
        "        output_sequence = model(source_batch.long(), source_batch.long())\n",
        "\n",
        "        # flatten\n",
        "        output_sequence = output_sequence.view(-1, vocab_size)\n",
        "        target_sequence = source_batch.view(-1).long()\n",
        "\n",
        "        loss = criterion(output_sequence, target_sequence)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        total_accuracy += calculate_accuracy(output_sequence, target_sequence)\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    avg_accuracy = total_accuracy / len(train_loader)\n",
        "    train_loss_list.append(avg_loss)\n",
        "    train_accuracy_list.append(avg_accuracy)\n",
        "\n",
        "    # val loop\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        total_val_loss = 0.0\n",
        "        total_val_accuracy = 0.0\n",
        "\n",
        "        for source_batch in tqdm(val_loader, desc=\"Validation Batches\", leave=False):\n",
        "\n",
        "            source_batch = torch.stack(source_batch, dim=0)\n",
        "\n",
        "\n",
        "            output_sequence = model(source_batch.long(), source_batch.long())\n",
        "\n",
        "            # flatten\n",
        "            output_sequence = output_sequence.view(-1, vocab_size)\n",
        "            target_sequence = source_batch.view(-1)\n",
        "\n",
        "            val_loss = criterion(output_sequence, target_sequence)\n",
        "            total_val_loss += val_loss.item()\n",
        "            total_val_accuracy += calculate_accuracy(output_sequence, target_sequence)\n",
        "\n",
        "        avg_val_loss = total_val_loss / len(val_loader)\n",
        "        avg_val_accuracy = total_val_accuracy / len(val_loader)\n",
        "        val_loss_list.append(avg_val_loss)\n",
        "        val_accuracy_list.append(avg_val_accuracy)\n",
        "\n",
        "    # plot every 5 epochs\n",
        "    if (epoch + 1) % plot_interval == 0 or epoch == num_epochs - 1:\n",
        "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {avg_loss:.4f}, Val Loss: {avg_val_loss:.4f}, Training Accuracy: {avg_accuracy:.4f}, Val Accuracy: {avg_val_accuracy:.4f}\")\n",
        "\n",
        "# final graphs\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(range(1, num_epochs + 1), train_loss_list, label='Training Loss')\n",
        "plt.plot(range(1, num_epochs + 1), val_loss_list, label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(range(1, num_epochs + 1), train_accuracy_list, label='Training Accuracy')\n",
        "plt.plot(range(1, num_epochs + 1), val_accuracy_list, label='Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        },
        "id": "fQz61tScRUHl",
        "outputId": "fecefe42-d4c4-47f9-eae4-db97cab0de16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epochs:   0%|          | 0/20 [00:00<?, ?it/s]\n",
            "Training Batches:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "Epochs:   0%|          | 0/20 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-73-9ed7690b6899>\u001b[0m in \u001b[0;36m<cell line: 24>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0msource_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0moutput_sequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;31m# flatten\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-72-7940a8eafbc1>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, source_sequence, target_sequence)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_sequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0membedded_source\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_sequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0membedded_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_sequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         return F.embedding(\n\u001b[0m\u001b[1;32m    163\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2208\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2209\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2210\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index out of range in self"
          ]
        }
      ]
    }
  ]
}