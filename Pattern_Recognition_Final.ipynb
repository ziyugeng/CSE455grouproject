{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1. Load all the necessary functions"
      ],
      "metadata": {
        "id": "LJLks1ivtlPN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TfErQcl66_yl"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "from sklearn.model_selection import train_test_split\n",
        "import requests\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. import CNN/Daily Mail dataset, from https://huggingface.co/datasets/cnn_dailymail"
      ],
      "metadata": {
        "id": "bbWP2rA3uDUm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "API_URL = \"https://datasets-server.huggingface.co/splits?dataset=cnn_dailymail\"\n",
        "TRAIN_API_URL = \"https://datasets-server.huggingface.co/rows?dataset=cnn_dailymail&config=1.0.0&split=train&offset=0&limit=100\"\n",
        "VAL_API_URL = \"https://datasets-server.huggingface.co/rows?dataset=cnn_dailymail&config=1.0.0&split=validation&offset=0&limit=100\"\n",
        "TEST_API_URL = \"https://datasets-server.huggingface.co/rows?dataset=cnn_dailymail&config=1.0.0&split=test&offset=0&limit=100\"\n",
        "\n",
        "def fetch_data(api_url):\n",
        "    response = requests.get(api_url)\n",
        "    return response.json()\n",
        "\n",
        "# Fetch train data and target summaries\n",
        "print(\"Fetching train data...\")\n",
        "train_data = fetch_data(TRAIN_API_URL)\n",
        "train_summaries = [example['row']['highlights'] for example in train_data['rows']]\n",
        "train_texts = [example['row']['article'] for example in train_data['rows']]\n",
        "print(\"Train data fetched successfully.\")\n",
        "\n",
        "# Print all the summaries and texts for the train set\n",
        "print(\"Train Summaries and Texts:\")\n",
        "for i, (summary, text) in enumerate(zip(train_summaries, train_texts), start=1):\n",
        "    print(f\"Example {i}:\")\n",
        "    print(f\"Summary: {summary}\")\n",
        "    print(f\"Text: {text}\")\n",
        "    print()\n",
        "\n",
        "# Fetch val data and target summaries\n",
        "print(\"Fetching validation data...\")\n",
        "val_data = fetch_data(VAL_API_URL)\n",
        "val_summaries = [example['row']['highlights'] for example in val_data['rows']]\n",
        "val_texts = [example['row']['article'] for example in val_data['rows']]\n",
        "print(\"Validation data fetched successfully.\")\n",
        "\n",
        "# Print all the summaries and texts for the validation set\n",
        "print(\"Validation Summaries and Texts:\")\n",
        "for i, (summary, text) in enumerate(zip(val_summaries, val_texts), start=1):\n",
        "    print(f\"Example {i}:\")\n",
        "    print(f\"Summary: {summary}\")\n",
        "    print(f\"Text: {text}\")\n",
        "    print()\n",
        "\n",
        "# Fetch test data and target summaries\n",
        "print(\"Fetching test data...\")\n",
        "test_data = fetch_data(TEST_API_URL)\n",
        "test_summaries = [example['row']['highlights'] for example in test_data['rows']]\n",
        "test_texts = [example['row']['article'] for example in test_data['rows']]\n",
        "print(\"Test data fetched successfully.\")\n",
        "\n",
        "# Print all the summaries and texts for the test set\n",
        "print(\"Test Summaries and Texts:\")\n",
        "for i, (summary, text) in enumerate(zip(test_summaries, test_texts), start=1):\n",
        "    print(f\"Example {i}:\")\n",
        "    print(f\"Summary: {summary}\")\n",
        "    print(f\"Text: {text}\")\n",
        "    print()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "iFuCrCTui8VL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "import requests\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Preprocessing functions\n",
        "\n",
        "def preprocess_text(text):\n",
        "    words = word_tokenize(text)\n",
        "    table = str.maketrans('', '', string.punctuation)\n",
        "    words = [word.translate(table) for word in words]\n",
        "    words = [word.lower() for word in words]\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    words = [word for word in words if word not in stop_words]\n",
        "    words = [word for word in words if len(word) > 1]\n",
        "    return words\n",
        "\n",
        "def pad_or_truncate_text(text, max_length):\n",
        "    preprocessed_words = preprocess_text(text)\n",
        "    if len(preprocessed_words) > max_length:\n",
        "        preprocessed_words = preprocessed_words[:max_length]\n",
        "    elif len(preprocessed_words) < max_length:\n",
        "        padding_length = max_length - len(preprocessed_words)\n",
        "        for _ in range(padding_length):\n",
        "            preprocessed_words.append('<PAD>')\n",
        "    return preprocessed_words\n",
        "\n",
        "\n",
        "def preprocess_target_summaries(summaries, max_length):\n",
        "    preprocessed_summaries = []\n",
        "    for summary in summaries:\n",
        "        preprocessed_summary = pad_or_truncate_text(summary, max_length)\n",
        "        preprocessed_summaries.append(preprocessed_summary)\n",
        "    return preprocessed_summaries\n",
        "\n",
        "\n",
        "\n",
        "# Fetch train data and target summaries\n",
        "train_data = fetch_data(TRAIN_API_URL)\n",
        "train_summaries = [example['row']['highlights'] for example in train_data['rows']]\n",
        "train_texts = [example['row']['article'] for example in train_data['rows']]\n",
        "\n",
        "# Fetch val data and target summaries\n",
        "val_data = fetch_data(VAL_API_URL)\n",
        "val_summaries = [example['row']['highlights'] for example in val_data['rows']]\n",
        "val_texts = [example['row']['article'] for example in val_data['rows']]\n",
        "\n",
        "# Fetch test data and target summaries\n",
        "test_data = fetch_data(TEST_API_URL)\n",
        "test_summaries = [example['row']['highlights'] for example in test_data['rows']]\n",
        "test_texts = [example['row']['article'] for example in test_data['rows']]\n",
        "\n",
        "# Preprocess article texts for each split\n",
        "max_length = 512\n",
        "train_texts = [pad_or_truncate_text(article_text, max_length) for article_text in train_texts]\n",
        "val_texts = [pad_or_truncate_text(article_text, max_length) for article_text in val_texts]\n",
        "test_texts = [pad_or_truncate_text(article_text, max_length) for article_text in test_texts]\n",
        "\n",
        "# Preprocess target summaries for each split\n",
        "train_targets = preprocess_target_summaries(train_summaries, max_length)\n",
        "val_targets = preprocess_target_summaries(val_summaries, max_length)\n",
        "test_targets = preprocess_target_summaries(test_summaries, max_length)\n",
        "\n",
        "# Vocabulary size\n",
        "vocabulary = set()\n",
        "for text in train_texts:\n",
        "    vocabulary.update(text)\n",
        "vocab_size = len(vocabulary)\n",
        "print(\"Vocabulary size:\", vocab_size)\n",
        "\n",
        "# Print preprocessed data\n",
        "print(\"Train Texts:\", train_texts)\n",
        "print(\"Train Targets:\", train_targets)\n",
        "print(\"Val Texts:\", val_texts)\n",
        "print(\"Val Targets:\", val_targets)\n",
        "print(\"Test Texts:\", test_texts)\n",
        "print(\"Test Targets:\", test_targets)\n"
      ],
      "metadata": {
        "id": "v-XlaAC3HJ4e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Represent text as word embeddings\n",
        "\n",
        "# -Word embeddings examples are Word2Vec, GloVe, FastText, and represent each word as a dense vector.\n",
        "# follow https://pytorch.org/tutorials/beginner/nlp/word_embeddings_tutorial.html.\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "vocab_size = 100000\n",
        "embedding_dim = 256\n",
        "hidden_dim = 256\n",
        "torch.manual_seed(1)\n",
        "\n",
        "# List of train texts\n",
        "train_preprocessed_text = []\n",
        "for example in train_data['rows']:\n",
        "    article_text = example['row']['article']\n",
        "    train_preprocessed_text.append(pad_or_truncate_text(article_text, max_length))\n",
        "\n",
        "# List of val texts\n",
        "val_preprocessed_text = []\n",
        "for example in val_data['rows']:\n",
        "    article_text = example['row']['article']\n",
        "    val_preprocessed_text.append(pad_or_truncate_text(article_text, max_length))\n",
        "\n",
        "# List of test texts\n",
        "test_preprocessed_text = []\n",
        "for example in test_data['rows']:\n",
        "    article_text = example['row']['article']\n",
        "    test_preprocessed_text.append(pad_or_truncate_text(article_text, max_length))\n",
        "\n",
        "# Build vocabulary from both texts and summaries\n",
        "all_texts_and_summaries = train_preprocessed_text + val_preprocessed_text + test_preprocessed_text + train_summaries + val_summaries + test_summaries\n",
        "word_freq = {}  # A dictionary to store word frequencies\n",
        "\n",
        "for sentence in all_texts_and_summaries:\n",
        "    for word in sentence:\n",
        "        if word not in word_freq:\n",
        "            word_freq[word] = 0\n",
        "        word_freq[word] += 1\n",
        "\n",
        "# Sort words based on frequency in descending order\n",
        "sorted_words = sorted(word_freq.keys(), key=lambda x: word_freq[x], reverse=True)\n",
        "\n",
        "# Take only the top vocab_size - 1 words, and add an OOV token\n",
        "sorted_words = sorted_words[:vocab_size - 1] + ['<OOV>']\n",
        "\n",
        "voc = set(sorted_words)\n",
        "word_to_num = {word: i for i, word in enumerate(voc)}\n",
        "word_to_num['<SOS>'] = len(word_to_num)\n",
        "\n",
        "\n",
        "def sentence_to_indices(sentence):\n",
        "    return [word_to_num.get(word, word_to_num['<OOV>']) for word in sentence]\n",
        "\n",
        "class wordembedding(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim):\n",
        "        super(wordembedding, self).__init__()\n",
        "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.vocab_size = vocab_size\n",
        "\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        return self.embeddings(inputs)\n",
        "\n",
        "# Create the model and the optimizer\n",
        "word_model = wordembedding(len(voc) + 1, embedding_dim)\n",
        "optimizer = optim.SGD(word_model.parameters(), lr=0.001)\n",
        "print(word_model.embeddings.weight.size(0))\n",
        "\n",
        "\n",
        "# ... (previous code remains unchanged)\n",
        "\n",
        "# Loop over train_targets and generate embeddings for summaries\n",
        "train_summary_embeddings_list = []\n",
        "for summary in train_targets:\n",
        "    summary_idxs = [word_to_num.get(word, word_to_num['<OOV>']) for word in summary]  # Get the index of each word in the summary\n",
        "    summary_idxs = torch.tensor(summary_idxs, dtype=torch.long)  # Convert the list to tensor outside the loop\n",
        "    embeddings = word_model(summary_idxs)\n",
        "    train_summary_embeddings_list.append(embeddings)  # Store the embeddings\n",
        "\n",
        "# Loop over val_targets and generate embeddings for summaries\n",
        "val_summary_embeddings_list = []\n",
        "for summary in val_targets:\n",
        "    summary_idxs = [word_to_num.get(word, word_to_num['<OOV>']) for word in summary]  # Get the index of each word in the summary\n",
        "    summary_idxs = torch.tensor(summary_idxs, dtype=torch.long)  # Convert the list to tensor outside the loop\n",
        "    embeddings = word_model(summary_idxs)\n",
        "    val_summary_embeddings_list.append(embeddings)  # Store the embeddings\n",
        "\n",
        "# Loop over test_targets and generate embeddings for summaries\n",
        "test_summary_embeddings_list = []\n",
        "for summary in test_targets:\n",
        "    summary_idxs = [word_to_num.get(word, word_to_num['<OOV>']) for word in summary]  # Get the index of each word in the summary\n",
        "    summary_idxs = torch.tensor(summary_idxs, dtype=torch.long)  # Convert the list to tensor outside the loop\n",
        "    embeddings = word_model(summary_idxs)\n",
        "    test_summary_embeddings_list.append(embeddings)  # Store the embeddings\n",
        "\n",
        "# Convert lists to PyTorch tensors for both texts and summaries\n",
        "train_summary_embeddings_tensor = torch.stack(train_summary_embeddings_list)\n",
        "val_summary_embeddings_tensor = torch.stack(val_summary_embeddings_list)\n",
        "test_summary_embeddings_tensor = torch.stack(test_summary_embeddings_list)\n",
        "\n",
        "train_text_embeddings_list = []\n",
        "val_text_embeddings_list = []\n",
        "test_text_embeddings_list = []\n",
        "\n",
        "# Loop over train_preprocessed_text and generate embeddings for texts\n",
        "for sentence in train_preprocessed_text:\n",
        "    sentence_idxs = [word_to_num[word] for word in sentence]  # Get the index of each word in the sentence\n",
        "    sentence_idxs = torch.tensor(sentence_idxs, dtype=torch.long)  # Convert the list to tensor outside the loop\n",
        "    embeddings = word_model(sentence_idxs)\n",
        "    train_text_embeddings_list.append(embeddings)  # Store the embeddings\n",
        "\n",
        "# Loop over val_preprocessed_text and generate embeddings for texts\n",
        "for sentence in val_preprocessed_text:\n",
        "    sentence_idxs = [word_to_num[word] for word in sentence]  # Get the index of each word in the sentence\n",
        "    sentence_idxs = torch.tensor(sentence_idxs, dtype=torch.long)  # Convert the list to tensor outside the loop\n",
        "    embeddings = word_model(sentence_idxs)\n",
        "    val_text_embeddings_list.append(embeddings)  # Store the embeddings\n",
        "\n",
        "# Loop over test_preprocessed_text and generate embeddings for texts\n",
        "for sentence in test_preprocessed_text:\n",
        "    sentence_idxs = [word_to_num[word] for word in sentence]  # Get the index of each word in the sentence\n",
        "    sentence_idxs = torch.tensor(sentence_idxs, dtype=torch.long)  # Convert the list to tensor outside the loop\n",
        "    embeddings = word_model(sentence_idxs)\n",
        "    test_text_embeddings_list.append(embeddings)  # Store the embeddings\n",
        "\n",
        "# Convert lists to PyTorch tensors for texts\n",
        "train_text_embeddings_tensor = torch.stack(train_text_embeddings_list).to(torch.long)  # Specify dtype=torch.long\n",
        "val_text_embeddings_tensor = torch.stack(val_text_embeddings_list).to(torch.long)  # Specify dtype=torch.long\n",
        "test_text_embeddings_tensor = torch.stack(test_text_embeddings_list).to(torch.long)  # Specify dtype=torch.long\n",
        "\n",
        "\n",
        "# print embeddings\n",
        "print(\"Train Summary Embeddings:\")\n",
        "print(train_summary_embeddings_tensor)\n",
        "\n",
        "print(\"Validation Summary Embeddings:\")\n",
        "print(val_summary_embeddings_tensor)\n",
        "\n",
        "print(\"Test Summary Embeddings:\")\n",
        "print(test_summary_embeddings_tensor)\n",
        "\n",
        "print(\"Train Text Embeddings:\")\n",
        "print(train_text_embeddings_tensor)\n",
        "\n",
        "print(\"Validation Text Embeddings:\")\n",
        "print(val_text_embeddings_tensor)\n",
        "\n",
        "print(\"Test Text Embeddings:\")\n",
        "print(test_text_embeddings_tensor)\n",
        "\n",
        "train_summary_embeddings = train_summary_embeddings_tensor\n",
        "val_summary_embeddings = val_summary_embeddings_tensor\n",
        "test_summary_embeddings = test_summary_embeddings_tensor\n",
        "train_text_embeddings = train_text_embeddings_tensor\n",
        "val_text_embeddings = val_text_embeddings_tensor\n",
        "test_text_embeddings = test_text_embeddings_tensor\n",
        "\n"
      ],
      "metadata": {
        "id": "gM2YPK7UNX3l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "# batch size\n",
        "batch_size = 32\n",
        "\n",
        "def pad_sequence(emb_list, max_length):\n",
        "    padded_tensors = []\n",
        "    for embeddings in emb_list:\n",
        "        # Pad with zero embeddings if the sequence is shorter than max_length\n",
        "        padding_length = max_length - embeddings.shape[0]\n",
        "        if padding_length > 0:\n",
        "            padding = torch.zeros((padding_length, embeddings.shape[1]))\n",
        "            padded_embeddings = torch.cat([embeddings, padding], dim=0)\n",
        "        else:\n",
        "            padded_embeddings = embeddings[:max_length]\n",
        "        padded_tensors.append(padded_embeddings)\n",
        "    return torch.stack(padded_tensors)\n",
        "\n",
        "def pad_collate_fn(batch):\n",
        "    (src, tgt) = zip(*batch)\n",
        "\n",
        "    # Convert to tensors\n",
        "    src_tensor = torch.stack(src)\n",
        "    tgt_tensor = torch.stack(tgt)\n",
        "\n",
        "    # Find the lengths\n",
        "    src_lengths = torch.tensor([len(x) for x in src])\n",
        "    tgt_lengths = torch.tensor([len(x) for x in tgt])\n",
        "\n",
        "    # Padding\n",
        "    src_padded = pad_sequence(src_tensor, max_length)\n",
        "    tgt_padded = pad_sequence(tgt_tensor, max_length)\n",
        "\n",
        "    return src_padded, src_lengths, tgt_padded, tgt_lengths\n",
        "\n",
        "\n",
        "# Convert lists of embeddings to padded tensors\n",
        "train_text_embeddings_padded = pad_sequence(train_text_embeddings_list, max_length)\n",
        "val_text_embeddings_padded = pad_sequence(val_text_embeddings_list, max_length)\n",
        "test_text_embeddings_padded = pad_sequence(test_text_embeddings_list, max_length)\n",
        "\n",
        "train_summary_embeddings_padded = pad_sequence(train_summary_embeddings_list, max_length)\n",
        "val_summary_embeddings_padded = pad_sequence(val_summary_embeddings_list, max_length)\n",
        "test_summary_embeddings_padded = pad_sequence(test_summary_embeddings_list, max_length)\n",
        "\n",
        "\n",
        "train_dataset = TensorDataset(train_text_embeddings, train_summary_embeddings)\n",
        "\n",
        "val_dataset = TensorDataset(val_text_embeddings, val_summary_embeddings)\n",
        "\n",
        "test_dataset = TensorDataset(test_text_embeddings, test_summary_embeddings)\n",
        "\n",
        "train_dataloader = DataLoader(TensorDataset(train_text_embeddings, train_summary_embeddings), batch_size=batch_size, collate_fn=pad_collate_fn)\n",
        "val_dataloader = DataLoader(TensorDataset(val_text_embeddings, val_summary_embeddings), batch_size=batch_size, collate_fn=pad_collate_fn)\n",
        "test_dataloader = DataLoader(TensorDataset(test_text_embeddings, test_summary_embeddings), batch_size=batch_size, collate_fn=pad_collate_fn)\n",
        "\n"
      ],
      "metadata": {
        "id": "Os4xibo0YQhL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "########  NN\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import matplotlib as plt\n",
        "\n",
        "# Get cpu, gpu or mps device for training.\n",
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "print(f\"Using {device} device\")\n",
        "\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, embedding_dim, hidden_dim):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
        "\n",
        "    def forward(self, embedded_input):\n",
        "        encoder_outputs, (hidden_state, cell_state) = self.rnn(embedded_input)\n",
        "        return encoder_outputs, (hidden_state, cell_state)\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, hidden_dim):\n",
        "        super(Attention, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.attn = nn.Linear(hidden_dim * 2, hidden_dim)\n",
        "        self.v = nn.Parameter(torch.rand(hidden_dim))\n",
        "\n",
        "    def forward(self, hidden_tuple, encoder_outputs):\n",
        "        hidden, _ = hidden_tuple\n",
        "        max_len = encoder_outputs.size(1)\n",
        "        h = hidden.repeat(max_len, 1, 1).transpose(0, 1)\n",
        "        encoder_outputs = encoder_outputs.transpose(1, 2)\n",
        "        attn_scores = F.softmax(torch.bmm(h, self.attn(encoder_outputs)), dim=2)\n",
        "        context = torch.bmm(attn_scores, encoder_outputs)\n",
        "        return context\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, embedding_dim, hidden_dim, vocab_size):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.rnn = nn.LSTM(embedding_dim + hidden_dim, hidden_dim, batch_first=True)\n",
        "        self.attention = Attention(hidden_dim)\n",
        "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
        "\n",
        "    def forward(self, embedded_target, hidden, encoder_outputs):\n",
        "        context = self.attention(hidden, encoder_outputs)\n",
        "        rnn_input = torch.cat((embedded_target, context.unsqueeze(1).repeat(1, embedded_target.size(1), 1)), dim=2)\n",
        "        decoder_outputs, hidden = self.rnn(rnn_input, hidden)\n",
        "        output_sequence = F.log_softmax(self.fc(decoder_outputs), dim=2)\n",
        "        return output_sequence, hidden\n",
        "\n",
        "\n",
        "class Seq2SeqAttentionWithEmbedding(nn.Module):\n",
        "    def __init__(self, src_vocab_size, tgt_vocab_size, src_embedding_dim, tgt_embedding_dim, hidden_dim):\n",
        "        super(Seq2SeqAttentionWithEmbedding, self).__init__()\n",
        "        self.embedding_source = nn.Embedding(src_vocab_size, src_embedding_dim)\n",
        "        self.embedding_target = nn.Embedding(tgt_vocab_size, tgt_embedding_dim)\n",
        "        self.encoder = Encoder(src_embedding_dim, hidden_dim)\n",
        "        self.decoder = Decoder(tgt_embedding_dim, hidden_dim, tgt_vocab_size)\n",
        "        self.attention = Attention(hidden_dim)\n",
        "\n",
        "    def forward(self, src_input, tgt_input):\n",
        "        embedded_source = self.embedding_source(src_input)\n",
        "        embedded_target = self.embedding_target(tgt_input)\n",
        "\n",
        "        encoder_outputs, hidden = self.encoder(embedded_source)\n",
        "        context = self.attention(hidden, encoder_outputs)\n",
        "        rnn_input = torch.cat((embedded_target, context), dim=2)\n",
        "\n",
        "        decoder_outputs, hidden = self.decoder.rnn(rnn_input, hidden)\n",
        "        output_sequence = F.log_softmax(self.decoder.fc(decoder_outputs), dim=2)\n",
        "        return output_sequence, hidden\n",
        "\n",
        "\n",
        "\n",
        "src_vocab_size = len(word_to_num)\n",
        "tgt_vocab_size = len(word_to_num)  # Use the same vocabulary for both source and target for now, you can create separate ones if needed\n",
        "model = Seq2SeqAttentionWithEmbedding(src_vocab_size, tgt_vocab_size, embedding_dim, embedding_dim, hidden_dim)\n",
        "\n",
        "\n",
        "# loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "j4RIQoRb-9o6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm as tqdm_module  # Importing tqdm with a different name to avoid conflicts\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 20\n",
        "\n",
        "train_accuracy_list = []\n",
        "val_accuracy_list = []\n",
        "train_loss_list = []\n",
        "val_loss_list = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    total_batches = 0\n",
        "    correct_predictions = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    with tqdm_module(total=len(train_dataloader), desc=f\"Epoch {epoch + 1}/{num_epochs}\", unit=\"batch\") as pbar:\n",
        "        for batch_idx, (src_input, tgt_input) in enumerate(train_dataloader):\n",
        "            for batch_idx, (src_input, src_lengths, tgt_input) in enumerate(train_dataloader):\n",
        "\n",
        "\n",
        "              batch_size = src_input.size(0)\n",
        "\n",
        "            # Calculate max_tgt_length dynamically for the current batch\n",
        "            max_tgt_length = tgt_input.size(1)\n",
        "\n",
        "            sos_token_idx = torch.tensor([word_to_num['<SOS>']], dtype=torch.long).to(device)  # Shape: [1]\n",
        "            sos_token_emb = word_model(sos_token_idx)  # Shape: [1, embedding_dim]\n",
        "            sos_token_emb = sos_token_emb.repeat(batch_size, 1, 1)  # Shape: [batch_size, 1, embedding_dim]\n",
        "\n",
        "            print(f\"Shape of sos_token_emb: {sos_token_emb.shape}\")\n",
        "            print(f\"Shape of tgt_input: {tgt_input.shape}\")\n",
        "            tgt_input_with_sos = torch.cat([sos_token_emb, tgt_input], dim=1)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            output_sequence, _ = model(src_input, tgt_input_with_sos[:, :-1, :])\n",
        "            tgt_input = tgt_input.contiguous().view(-1).to(torch.long)\n",
        "\n",
        "            loss = criterion(output_sequence, tgt_input)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            total_batches += 1\n",
        "\n",
        "            # calculate training accuracy\n",
        "            _, predicted = torch.max(output_sequence, 2)  # Use dim=2 to find max along time steps\n",
        "            correct_predictions += (predicted == tgt_input.view_as(predicted)).sum().item()\n",
        "            total_samples += tgt_input.size(0) * tgt_input.size(1)\n",
        "\n",
        "            pbar.update(1)\n",
        "\n",
        "    avg_loss = total_loss / total_batches\n",
        "    train_accuracy = correct_predictions / total_samples\n",
        "\n",
        "    train_accuracy_list.append(train_accuracy)\n",
        "    train_loss_list.append(avg_loss)\n",
        "\n",
        "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Train Loss: {avg_loss:.4f}, Train Accuracy: {train_accuracy:.4f}\")\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    total_batches = 0\n",
        "    correct_predictions = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (src_input, src_lengths, tgt_input) in enumerate(val_dataloader):\n",
        "            src_input, tgt_input = src_input.to(device).to(torch.long), tgt_input.to(device).to(torch.long)\n",
        "\n",
        "\n",
        "            output_sequence, _ = model(src_input, tgt_input[:, :-1])\n",
        "\n",
        "            output_sequence = output_sequence.contiguous().view(-1, output_sequence.size(-1))\n",
        "            tgt_input = tgt_input.contiguous().view(-1).to(torch.long)  # Convert to 1D LongTensor\n",
        "\n",
        "            loss = criterion(output_sequence, tgt_input)\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            total_batches += 1\n",
        "\n",
        "            # Calculate validation accuracy\n",
        "            _, predicted = torch.max(output_sequence, 1)\n",
        "            correct_predictions += (predicted == tgt_input).sum().item()\n",
        "            total_samples += tgt_input.size(0)\n",
        "\n",
        "    avg_loss = total_loss / total_batches\n",
        "    val_accuracy = correct_predictions / total_samples\n",
        "\n",
        "    val_accuracy_list.append(val_accuracy)\n",
        "    val_loss_list.append(avg_loss)\n",
        "\n",
        "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Validation Loss: {avg_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "    # Graphs every 5 epochs\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        plt.figure(figsize=(12, 4))\n",
        "\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.plot(range(1, epoch + 2), train_accuracy_list, label=\"Train Accuracy\")\n",
        "        plt.plot(range(1, epoch + 2), val_accuracy_list, label=\"Validation Accuracy\")\n",
        "        plt.xlabel(\"Epoch\")\n",
        "        plt.ylabel(\"Accuracy\")\n",
        "        plt.legend()\n",
        "        plt.title(\"Training and Validation Accuracy vs. Epoch\")\n",
        "\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.plot(range(1, epoch + 2), train_loss_list, label=\"Train Loss\")\n",
        "        plt.plot(range(1, epoch + 2), val_loss_list, label=\"Validation Loss\")\n",
        "        plt.xlabel(\"Epoch\")\n",
        "        plt.ylabel(\"Loss\")\n",
        "        plt.legend()\n",
        "        plt.title(\"Training and Validation Loss vs. Epoch\")\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "# Final graphs\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(range(1, num_epochs + 1), train_accuracy_list, label=\"Train Accuracy\")\n",
        "plt.plot(range(1, num_epochs + 1), val_accuracy_list, label=\"Validation Accuracy\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.title(\"Training and Validation Accuracy vs. Epoch\")\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(range(1, num_epochs + 1), train_loss_list, label=\"Train Loss\")\n",
        "plt.plot(range(1, num_epochs + 1), val_loss_list, label=\"Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.title(\"Training and Validation Loss vs. Epoch\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "ZgAas3pnM_nJ",
        "outputId": "67837a12-7942-44af-b06a-e44a08a1a575"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/20:   0%|          | 0/4 [00:00<?, ?batch/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-232-35518259c523>\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtqdm_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"Epoch {epoch + 1}/{num_epochs}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"batch\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msrc_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_input\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msrc_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_lengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_input\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the index of <SOS>\n",
        "sos_index = word_to_num['<SOS>']\n",
        "\n",
        "# Get the embedding of <SOS>\n",
        "sos_embedding = word_model(torch.tensor([sos_index]))\n",
        "\n",
        "print(\"Shape of <SOS> embedding:\")\n",
        "print(sos_embedding.shape)\n",
        "\n",
        "# Get the embedding of a sentence\n",
        "sentence_embedding = word_model(torch.tensor(sentence_to_indices(train_preprocessed_text[0]), dtype=torch.long))\n",
        "\n",
        "print(\"Shape of sentence embedding:\")\n",
        "print(sentence_embedding.shape)\n"
      ],
      "metadata": {
        "id": "HTkpoDlupA9V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "first_batch = next(iter(train_dataloader))\n",
        "print(first_batch)\n"
      ],
      "metadata": {
        "id": "20wyItkmrUzO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}